<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>Session 1 - Introduction | Notes by nggih</title>
    <meta name="generator" content="VuePress 1.7.1">
    
    <meta name="description" content="blog">
    <meta name="theme-color" content="#3eaf7c">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black">
    
    <link rel="preload" href="/assets/css/0.styles.f1075b4d.css" as="style"><link rel="preload" href="/assets/js/app.808fae58.js" as="script"><link rel="preload" href="/assets/js/2.6d28419f.js" as="script"><link rel="preload" href="/assets/js/3.35e905b2.js" as="script"><link rel="prefetch" href="/assets/js/10.6b434eca.js"><link rel="prefetch" href="/assets/js/11.9a983a57.js"><link rel="prefetch" href="/assets/js/12.ddfe4e52.js"><link rel="prefetch" href="/assets/js/13.93f4e917.js"><link rel="prefetch" href="/assets/js/14.53346d06.js"><link rel="prefetch" href="/assets/js/15.16e8b4da.js"><link rel="prefetch" href="/assets/js/16.bbef83c6.js"><link rel="prefetch" href="/assets/js/17.b9469513.js"><link rel="prefetch" href="/assets/js/18.7687f5cf.js"><link rel="prefetch" href="/assets/js/4.cf35097d.js"><link rel="prefetch" href="/assets/js/5.4308a979.js"><link rel="prefetch" href="/assets/js/6.4236051c.js"><link rel="prefetch" href="/assets/js/7.aca205b7.js"><link rel="prefetch" href="/assets/js/8.3ec6bef6.js"><link rel="prefetch" href="/assets/js/9.28c58c4b.js">
    <link rel="stylesheet" href="/assets/css/0.styles.f1075b4d.css">
  </head>
  <body>
    <div id="app" data-server-rendered="true"><div class="theme-container"><header class="navbar"><div class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/" class="home-link router-link-active"><!----> <span class="site-name">Notes by nggih</span></a> <div class="links"><div class="search-box"><input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div> <nav class="nav-links can-hide"><div class="nav-item"><a href="/guide/" class="nav-link">
  Guide
</a></div><div class="nav-item"><a href="/reinforcement-learning/" class="nav-link router-link-active">
  RL
</a></div><div class="nav-item"><a href="/writing/" class="nav-link">
  Writing
</a></div><div class="nav-item"><a href="/config/" class="nav-link">
  Config
</a></div><div class="nav-item"><a href="https://v1.vuepress.vuejs.org" target="_blank" rel="noopener noreferrer" class="nav-link external">
  VuePress
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></div> <!----></nav></div></header> <div class="sidebar-mask"></div> <aside class="sidebar"><nav class="nav-links"><div class="nav-item"><a href="/guide/" class="nav-link">
  Guide
</a></div><div class="nav-item"><a href="/reinforcement-learning/" class="nav-link router-link-active">
  RL
</a></div><div class="nav-item"><a href="/writing/" class="nav-link">
  Writing
</a></div><div class="nav-item"><a href="/config/" class="nav-link">
  Config
</a></div><div class="nav-item"><a href="https://v1.vuepress.vuejs.org" target="_blank" rel="noopener noreferrer" class="nav-link external">
  VuePress
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></div> <!----></nav>  <ul class="sidebar-links"><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading open"><span>AWS DeepRacer Bootcamp x JML</span> <span class="arrow down"></span></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/reinforcement-learning/" aria-current="page" class="sidebar-link">Preface</a></li><li><a href="/reinforcement-learning/deepracer-1.html" aria-current="page" class="active sidebar-link">Session 1 - Introduction</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/reinforcement-learning/deepracer-1.html#what-is-reinforcement-learning" class="sidebar-link">What is Reinforcement Learning?</a></li><li class="sidebar-sub-header"><a href="/reinforcement-learning/deepracer-1.html#the-elements-of-reinforcement-learning" class="sidebar-link">The Elements of Reinforcement Learning</a></li><li class="sidebar-sub-header"><a href="/reinforcement-learning/deepracer-1.html#reward-function" class="sidebar-link">Reward function</a></li><li class="sidebar-sub-header"><a href="/reinforcement-learning/deepracer-1.html#aws-deepracer-league-in-2020" class="sidebar-link">AWS DeepRacer League in 2020!</a></li></ul></li><li><a href="/reinforcement-learning/deepracer-2.html" class="sidebar-link">Session 2 - Markov Decision Process</a></li><li><a href="/reinforcement-learning/deepracer-3.html" class="sidebar-link">Session 3 - Hyperparams</a></li></ul></section></li></ul> </aside> <main class="page"> <div class="theme-default-content content__default"><h1 id="session-1-introduction"><a href="#session-1-introduction" class="header-anchor">#</a> Session 1 - Introduction</h1> <h2 id="what-is-reinforcement-learning"><a href="#what-is-reinforcement-learning" class="header-anchor">#</a> What is Reinforcement Learning?</h2> <p>Reinforcement learning is a part of machine learning, which enables the model/machine to learn about its surroundings through its actions based on maximum reward mechanism. Reinforcement concept itself came from psychology, which is about conditioning based on rewards and punishments to get the desired results. This is quite different than the other machine learning domains, the supervised learning and unsupervised learning.</p> <p>Supervised learning uses labels as the guidances for the model to learn. Meanwhile, the unsupervised learning learns from the intrinsic features from the data without the human-annotated labels. The most distinguished differences from reinforcement learning are the reinforcement mechanism itself and the exploration-exploitation process, which do not exist in supervised or unsupervised learning.</p> <h2 id="the-elements-of-reinforcement-learning"><a href="#the-elements-of-reinforcement-learning" class="header-anchor">#</a> The Elements of Reinforcement Learning</h2> <p><img src="/assets/img/rl_elements.e8b7701d.png" alt="Elements"></p> <p><em>Figure from Donnie Prakoso Session 1 slide</em></p> <p>All the reinforcement learning has these basic elements:</p> <ul><li>Agent:
The virtual car (neural network model) in simulation or the physical device (OpenVino AWS DeepRacer car).</li> <li>Environment:
The race track (coordinates in simulation) or the physical track.</li> <li>State:
Agent's snapshot at the point of time from the environment. There are current state, previous state and future state. In here, it is the image that the camera takes.</li> <li>Action:
The decision which the agent will choose. For example, the speed and the steering angle.</li> <li>Reward:
The incentives for particular behaviors. This can be a positive reward or negative reward (punishment). We define the reward function for the agent.</li></ul> <p>As the main goal in reinforcement learning is to get the maximum rewards, there is a trade-off in reinforcement learning which is between the exploration and the exploitation. When the agent explores too much, it won't maximizes the reward as all actions might not give the maximum result. And when the agent exploits too much, it might not maximizes the right action. The agent should balances between exploration and exploitation.</p> <p><img src="/assets/img/rl_elements_learning.768b6499.png" alt="Learning"></p> <p><em>Figure from Donnie Prakoso Session 1 slide</em></p> <p>In a bigger picture, the learning in reinforcement learning goes like this. The agent will choose an action based on the environment state, which returns the reward and then goes to next state.</p> <h3 id="scores"><a href="#scores" class="header-anchor">#</a> Scores</h3> <p>By using the reward function, we can give a score to each behavior. For example, we want to give a higher reward if the agent maintains a high speed and penalize with lower reward if the agent goes slow.</p> <h3 id="episode"><a href="#episode" class="header-anchor">#</a> Episode</h3> <p>If the agent reaches a stop state, where it reaches its destination or off-track, the rewards will be totaled/ summed. It is called an episode.</p> <h3 id="iteration"><a href="#iteration" class="header-anchor">#</a> Iteration</h3> <p>Learning in machine learning takes some iterations for the model to converge to its optimum points. This is the same in reinforcement learning where it takes some iterations to optimize those rewards that have been accumulated. In every n-th of the iteration, the model matrix will be updated accordingly.</p> <h2 id="reward-function"><a href="#reward-function" class="header-anchor">#</a> Reward function</h2> <p>It is important to tweak the reward function so the agent will maximize the behavior we want to enforce. There are several parameters that we can adjust.</p> <p><img src="/assets/img/rl_rewardfunction-params.5c836896.png" alt="Params"></p> <p><em><a href="https://d2k9g1efyej86q.cloudfront.net/" target="_blank" rel="noopener noreferrer">Figure from AWS DeepRacer tutorial<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></em></p> <p>More detailed explanation is available on the AWS DeepRacer documeentation. I will put a separate blog post regarding the params and my findings after this bootcamp is over.</p> <h2 id="aws-deepracer-league-in-2020"><a href="#aws-deepracer-league-in-2020" class="header-anchor">#</a> AWS DeepRacer League in 2020!</h2> <p><img src="/assets/img/rl_aws-deepracer-league.0c825b6a.png" alt="League"> <em>Figure from Donnie Prakoso Session 1 slide</em></p> <p>I am participating in the online virtual circuit in the time trial race formats. I really enjoy training the DeepRacer agent, it is really fun to watch, you can see the simulation video stream of your agent struggling to maximize the rewards.</p> <p><img src="/assets/img/snapshot.7058ba9d.jpg" alt="Snaps"></p></div> <footer class="page-edit"><!----> <div class="last-updated"><span class="prefix">Last Updated:</span> <span class="time">10/29/2020, 4:44:04 PM</span></div></footer> <div class="page-nav"><p class="inner"><span class="prev">
      ←
      <a href="/reinforcement-learning/" class="prev router-link-active">
        Preface
      </a></span> <span class="next"><a href="/reinforcement-learning/deepracer-2.html">
        Session 2 - Markov Decision Process
      </a>
      →
    </span></p></div> </main></div><div class="global-ui"></div></div>
    <script src="/assets/js/app.808fae58.js" defer></script><script src="/assets/js/2.6d28419f.js" defer></script><script src="/assets/js/3.35e905b2.js" defer></script>
  </body>
</html>
